{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical patient columns: Index(['PATIENT_ID', 'LYMPH_NODES_EXAMINED_POSITIVE', 'NPI', 'CELLULARITY',\n",
      "       'CHEMOTHERAPY', 'COHORT', 'ER_IHC', 'HER2_SNP6', 'HORMONE_THERAPY',\n",
      "       'INFERRED_MENOPAUSAL_STATE', 'SEX', 'INTCLUST', 'AGE_AT_DIAGNOSIS',\n",
      "       'OS_MONTHS', 'OS_STATUS', 'CLAUDIN_SUBTYPE', 'THREEGENE',\n",
      "       'VITAL_STATUS', 'LATERALITY', 'RADIO_THERAPY', 'HISTOLOGICAL_SUBTYPE',\n",
      "       'BREAST_SURGERY', 'RFS_MONTHS', 'RFS_STATUS'],\n",
      "      dtype='object')\n",
      "Clinical sample columns: Index(['PATIENT_ID', 'SAMPLE_ID', 'CANCER_TYPE', 'CANCER_TYPE_DETAILED',\n",
      "       'ER_STATUS', 'HER2_STATUS', 'GRADE', 'ONCOTREE_CODE', 'PR_STATUS',\n",
      "       'SAMPLE_TYPE', 'TUMOR_SIZE', 'TUMOR_STAGE', 'TMB_NONSYNONYMOUS'],\n",
      "      dtype='object')\n",
      "Clinical data shape: (2509, 36)\n",
      "Initial CNA data shape: (22544, 2174)\n",
      "Transposed CNA data shape: (2174, 22544)\n",
      "Initial mRNA data shape: (20603, 1981)\n",
      "Transposed mRNA data shape: (1980, 20603)\n",
      "Mutation data shape: (17272, 45)\n",
      "Clinical data patient IDs: 2509\n",
      "CNA data patient IDs: 2174\n",
      "mRNA data patient IDs: 1980\n",
      "Patients in clinical and CNA data: 2173\n",
      "Patients in all three datasets: 1980\n",
      "Datasets are mergeable!\n",
      "Merged data shape: (1980, 51915)\n",
      "Preprocessed data saved as 'preprocessed_metabric.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "data_dir = \"./brca_metabric/\"  # Directory containing the files\n",
    "\n",
    "# Metadata and file mapping\n",
    "files = {\n",
    "    \"clinical_patient\": \"data_clinical_patient.txt\",\n",
    "    \"clinical_sample\": \"data_clinical_sample.txt\",\n",
    "    \"cna\": \"data_cna.txt\",\n",
    "    \"methylation\": \"data_methylation_promoters_rrbs.txt\",\n",
    "    \"mrna_expression\": \"data_mrna_illumina_microarray.txt\",\n",
    "    \"mrna_zscores\": \"data_mrna_illumina_microarray_zscores_ref_diploid_samples.txt\",\n",
    "    \"mutations\": \"data_mutations.txt\",\n",
    "}\n",
    "\n",
    "# Load clinical data\n",
    "def load_clinical_data():\n",
    "    # Load the clinical data files, skipping metadata rows (first few rows)\n",
    "    clinical_patient = pd.read_csv(data_dir + files[\"clinical_patient\"], sep=\"\\t\", skiprows=4)  # Skip metadata rows\n",
    "    clinical_sample = pd.read_csv(data_dir + files[\"clinical_sample\"], sep=\"\\t\", skiprows=4)  # Skip metadata rows\n",
    "    \n",
    "    # Strip spaces from column names\n",
    "    clinical_patient.columns = clinical_patient.columns.str.strip()\n",
    "    clinical_sample.columns = clinical_sample.columns.str.strip()\n",
    "    \n",
    "    # Check for the presence of 'PATIENT_ID' column in both files\n",
    "    print(\"Clinical patient columns:\", clinical_patient.columns)\n",
    "    print(\"Clinical sample columns:\", clinical_sample.columns)\n",
    "    \n",
    "    # Merge patient and sample data on the patient identifier\n",
    "    if 'PATIENT_ID' in clinical_patient.columns and 'PATIENT_ID' in clinical_sample.columns:\n",
    "        clinical_data = pd.merge(clinical_patient, clinical_sample, on=\"PATIENT_ID\", how=\"outer\")\n",
    "        print(\"Clinical data shape:\", clinical_data.shape)\n",
    "        return clinical_data\n",
    "    else:\n",
    "        raise KeyError(\"PATIENT_ID column is missing from one or both clinical data files\")\n",
    "\n",
    "# Load copy number alteration (CNA) data\n",
    "def load_cna_data():\n",
    "    cna_data = pd.read_csv(data_dir + files[\"cna\"], sep=\"\\t\", comment=\"#\", index_col=0)\n",
    "    print(\"Initial CNA data shape:\", cna_data.shape)\n",
    "\n",
    "    # Transpose the data\n",
    "    cna_data = cna_data.T\n",
    "    print(\"Transposed CNA data shape:\", cna_data.shape)\n",
    "    return cna_data\n",
    "\n",
    "# Load mRNA expression data\n",
    "def load_mrna_expression_data():\n",
    "    mrna_data = pd.read_csv(data_dir + files[\"mrna_expression\"], sep=\"\\t\", comment=\"#\", index_col=0)\n",
    "    print(\"Initial mRNA data shape:\", mrna_data.shape)\n",
    "    \n",
    "    # Transpose the data\n",
    "    mrna_data = mrna_data.drop(columns=[\"Entrez_Gene_Id\"]).T  # Remove `Entrez_Gene_Id` before transposing\n",
    "    print(\"Transposed mRNA data shape:\", mrna_data.shape)\n",
    "    return mrna_data\n",
    "\n",
    "# Load mutation data\n",
    "def load_mutation_data():\n",
    "    mutation_data = pd.read_csv(data_dir + files[\"mutations\"], sep=\"\\t\", comment=\"#\")\n",
    "    print(\"Mutation data shape:\", mutation_data.shape)\n",
    "    return mutation_data\n",
    "\n",
    "def check_mergeability(clinical_data, cna_data, mrna_data):\n",
    "    # Normalize patient identifiers in all datasets\n",
    "    clinical_data['PATIENT_ID'] = clinical_data['PATIENT_ID'].str.strip().str.upper()\n",
    "    cna_data.index = cna_data.index.str.strip().str.upper()\n",
    "    mrna_data.index = mrna_data.index.str.strip().str.upper()\n",
    "    \n",
    "    # Convert clinical_data to use PATIENT_ID as the index for consistency\n",
    "    clinical_index = set(clinical_data['PATIENT_ID'])\n",
    "    cna_index = set(cna_data.index)\n",
    "    mrna_index = set(mrna_data.index)\n",
    "\n",
    "    print(\"Clinical data patient IDs:\", len(clinical_index))\n",
    "    print(\"CNA data patient IDs:\", len(cna_index))\n",
    "    print(\"mRNA data patient IDs:\", len(mrna_index))\n",
    "    \n",
    "    # Check intersections\n",
    "    clinical_cna_intersection = clinical_index.intersection(cna_index)\n",
    "    all_intersection = clinical_cna_intersection.intersection(mrna_index)\n",
    "    \n",
    "    # Print debugging information\n",
    "    print(f\"Patients in clinical and CNA data: {len(clinical_cna_intersection)}\")\n",
    "    print(f\"Patients in all three datasets: {len(all_intersection)}\")\n",
    "    \n",
    "    # Check if merge is feasible\n",
    "    if len(all_intersection) > 0:\n",
    "        print(\"Datasets are mergeable!\")\n",
    "    else:\n",
    "        print(\"Datasets are not mergeable. Check your patient identifiers.\")\n",
    "    \n",
    "    return all_intersection\n",
    "\n",
    "\n",
    "# Preprocess clinical data\n",
    "def preprocess_clinical_data(data):\n",
    "    # Handle missing values\n",
    "    data = data.fillna(\"Unknown\")\n",
    "    # Exclude PATIENT_ID from one-hot encoding\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    categorical_columns = categorical_columns.drop('PATIENT_ID', errors='ignore')\n",
    "    # One-hot encode categorical variables\n",
    "    data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "    return data\n",
    "\n",
    "# Merge datasets\n",
    "def merge_datasets(clinical_data, cna_data, mrna_data):\n",
    "    # Ensure consistent identifiers\n",
    "    clinical_data['PATIENT_ID'] = clinical_data['PATIENT_ID'].str.strip().str.upper()\n",
    "    cna_data.index = cna_data.index.str.strip().str.upper()\n",
    "    mrna_data.index = mrna_data.index.str.strip().str.upper()\n",
    "\n",
    "    # Merge datasets\n",
    "    clinical_data = clinical_data.set_index(\"PATIENT_ID\")\n",
    "    merged_data = clinical_data.join(cna_data, how=\"inner\", rsuffix=\"_CNA\").join(mrna_data, how=\"inner\", rsuffix=\"_mRNA\")\n",
    "    \n",
    "    print(\"Merged data shape:\", merged_data.shape)\n",
    "    return merged_data\n",
    "\n",
    "# Main pipeline\n",
    "def main_pipeline():\n",
    "    # Load datasets\n",
    "    clinical_data = load_clinical_data()\n",
    "    cna_data = load_cna_data()\n",
    "    mrna_data = load_mrna_expression_data()\n",
    "    mutation_data = load_mutation_data()\n",
    "\n",
    "    # Check if datasets are mergeable\n",
    "    mergeable_ids = check_mergeability(clinical_data, cna_data, mrna_data)\n",
    "    if not mergeable_ids:\n",
    "        raise ValueError(\"No common patient IDs across the datasets. Cannot merge.\")\n",
    "\n",
    "    # Preprocess clinical data\n",
    "    clinical_data = preprocess_clinical_data(clinical_data)\n",
    "\n",
    "    # Merge datasets\n",
    "    merged_data = merge_datasets(clinical_data, cna_data, mrna_data)\n",
    "\n",
    "    # Save preprocessed data\n",
    "    merged_data.to_csv(data_dir + \"preprocessed_metabric.csv\", index=True)\n",
    "    print(\"Preprocessed data saved as 'preprocessed_metabric.csv'\")\n",
    "    return merged_data\n",
    "\n",
    "# Run the pipeline\n",
    "preprocessed_data = main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, matthews_corrcoef, average_precision_score\n",
    "\n",
    "def calculate_metrics(all_labels, all_predictions):\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    auc = roc_auc_score(all_labels, all_predictions)\n",
    "    prec = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    mcc = matthews_corrcoef(all_labels, all_predictions)\n",
    "    auprc = average_precision_score(all_labels, all_predictions)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"AUPRC: {auprc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files saved:\n",
      " - clinical_data.csv\n",
      " - cna_data.csv\n",
      " - mrna_data.csv\n",
      " - mrna_zscores.csv\n",
      " - labels.csv\n"
     ]
    }
   ],
   "source": [
    "# Process and save the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "data_dir = \"./brca_metabric/\"  # Directory containing the files\n",
    "\n",
    "# Metadata and file mapping\n",
    "files = {\n",
    "    \"clinical_patient\": \"data_clinical_patient.txt\",\n",
    "    \"clinical_sample\": \"data_clinical_sample.txt\",\n",
    "    \"cna\": \"data_cna.txt\",\n",
    "    \"mrna_expression\": \"data_mrna_illumina_microarray.txt\",\n",
    "    \"mrna_zscores\": \"data_mrna_illumina_microarray_zscores_ref_diploid_samples.txt\",\n",
    "}\n",
    "\n",
    "# Define survival threshold for binary classification\n",
    "SURVIVAL_THRESHOLD = 60  # 60 months\n",
    "\n",
    "def preprocess_clinical_data(clinical_data):\n",
    "    \"\"\"Preprocess clinical data: one-hot encoding, handle missing values.\"\"\"\n",
    "    clinical_data = clinical_data.fillna(\"Unknown\")  # Handle missing values\n",
    "    columns_to_drop = [\n",
    "    \"OS_STATUS\", \"RFS_MONTHS\", \"RFS_STATUS\"\n",
    "    , \"VITAL_STATUS\", \"CHEMOTHERAPY\", \"HORMONE_THERAPY\", \"RADIO_THERAPY\"\n",
    "    , \"SAMPLE_ID\", \"CANCER_TYPE\", \"CANCER_TYPE_DETAILED\", \"ONCOTREE_CODE\"\n",
    "    , \"SAMPLE_TYPE\"\n",
    "    , \"TMB_NONSYNONYMOUS\", \"HER2_SNP6\"\n",
    "    ]\n",
    "\n",
    "    clinical_data = clinical_data.drop(columns=columns_to_drop)\n",
    "\n",
    "    categorical_columns = clinical_data.select_dtypes(include=[\"object\"]).columns\n",
    "    categorical_columns = categorical_columns.drop(\"PATIENT_ID\", errors=\"ignore\")\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    clinical_data = pd.get_dummies(clinical_data, columns=categorical_columns, drop_first=True)\n",
    "    return clinical_data\n",
    "\n",
    "def load_and_process_data():\n",
    "    # Load clinical data\n",
    "    clinical_patient = pd.read_csv(data_dir + files[\"clinical_patient\"], sep=\"\\t\", skiprows=4)\n",
    "    clinical_sample = pd.read_csv(data_dir + files[\"clinical_sample\"], sep=\"\\t\", skiprows=4)\n",
    "    clinical_patient.columns = clinical_patient.columns.str.strip()\n",
    "    clinical_sample.columns = clinical_sample.columns.str.strip()\n",
    "\n",
    "    # Merge clinical data\n",
    "    clinical_data = pd.merge(clinical_patient, clinical_sample, on=\"PATIENT_ID\", how=\"outer\")\n",
    "\n",
    "    # Load CNA data\n",
    "    cna_data = pd.read_csv(data_dir + files[\"cna\"], sep=\"\\t\", comment=\"#\", index_col=0).T\n",
    "\n",
    "    # Load mRNA data\n",
    "    mrna_data = pd.read_csv(data_dir + files[\"mrna_expression\"], sep=\"\\t\", comment=\"#\", index_col=0)\n",
    "    mrna_data = mrna_data.drop(columns=[\"Entrez_Gene_Id\"]).T  # Remove non-feature columns\n",
    "\n",
    "    # load mrna zscores\n",
    "    mrna_zscores = pd.read_csv(data_dir + files[\"mrna_zscores\"], sep=\"\\t\", comment=\"#\", index_col=0)\n",
    "    mrna_zscores = mrna_zscores.drop(columns=[\"Entrez_Gene_Id\"]).T  # Remove non-feature columns\n",
    "\n",
    "    # Ensure consistent identifiers\n",
    "    clinical_data[\"PATIENT_ID\"] = clinical_data[\"PATIENT_ID\"].str.strip().str.upper()\n",
    "    cna_data.index = cna_data.index.str.strip().str.upper()\n",
    "    mrna_data.index = mrna_data.index.str.strip().str.upper()\n",
    "    mrna_zscores.index = mrna_zscores.index.str.strip().str.upper()\n",
    "\n",
    "    # Align data based on common patient IDs\n",
    "    common_ids = sorted(list(set(clinical_data[\"PATIENT_ID\"]).intersection(cna_data.index, mrna_data.index)))  # Sorted\n",
    "    clinical_data = clinical_data[clinical_data[\"PATIENT_ID\"].isin(common_ids)].sort_values(by=\"PATIENT_ID\")\n",
    "    cna_data = cna_data.loc[common_ids].sort_index()\n",
    "    mrna_data = mrna_data.loc[common_ids].sort_index()\n",
    "    mrna_zscores = mrna_zscores.loc[common_ids].sort_index()\n",
    "\n",
    "    # Preprocess clinical data\n",
    "    clinical_data = preprocess_clinical_data(clinical_data)\n",
    "\n",
    "    # Extract the label for survival prediction\n",
    "    labels = clinical_data[[\"OS_MONTHS\"]].copy()\n",
    "    labels[\"SURVIVAL_BINARY\"] = (labels[\"OS_MONTHS\"] >= SURVIVAL_THRESHOLD).astype(int)\n",
    "    labels[\"PATIENT_ID\"] = clinical_data.index  # Add PATIENT_ID as a column\n",
    "    labels = labels[[\"PATIENT_ID\", \"SURVIVAL_BINARY\"]]  # Include PATIENT_ID for alignment\n",
    "\n",
    "    # Drop unnecessary columns from clinical data\n",
    "    clinical_data = clinical_data.drop(columns=[\"OS_MONTHS\"], errors=\"ignore\")\n",
    "\n",
    "    # Save processed files\n",
    "    clinical_data.to_csv(data_dir + \"dataset/clinical_data.csv\", index=True)\n",
    "    cna_data.to_csv(data_dir + \"dataset/cna_data.csv\", index=True)\n",
    "    mrna_data.to_csv(data_dir + \"dataset/mrna_data.csv\", index=True)\n",
    "    mrna_zscores.to_csv(data_dir + \"dataset/mrna_zscores.csv\", index=True)\n",
    "    labels.to_csv(data_dir + \"dataset/labels.csv\", index=False)\n",
    "\n",
    "    print(\"Processed files saved:\")\n",
    "    print(\" - clinical_data.csv\")\n",
    "    print(\" - cna_data.csv\")\n",
    "    print(\" - mrna_data.csv\")\n",
    "    print(\" - mrna_zscores.csv\")\n",
    "    print(\" - labels.csv\")\n",
    "\n",
    "# Run the processing pipeline\n",
    "load_and_process_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for Breast Cancer data\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, clinical_path, cna_path, mrna_path, labels_path):\n",
    "        # Load data\n",
    "        self.clinical_data = pd.read_csv(clinical_path)\n",
    "        self.cna_data = pd.read_csv(cna_path, index_col=0)  # Load CNA with index as PATIENT_ID\n",
    "        self.mrna_data = pd.read_csv(mrna_path, index_col=0)  # Load mRNA with index as PATIENT_ID\n",
    "        self.labels = pd.read_csv(labels_path)\n",
    "        \n",
    "        # Drop the PATIENT_ID column from clinical data if it exists\n",
    "        if \"PATIENT_ID\" in self.clinical_data.columns:\n",
    "            self.clinical_data = self.clinical_data.drop(columns=[\"PATIENT_ID\"])\n",
    "        \n",
    "        # Reset the index for CNA and mRNA data to avoid including PATIENT_ID\n",
    "        self.cna_data = self.cna_data.reset_index(drop=True)\n",
    "        self.mrna_data = self.mrna_data.reset_index(drop=True)\n",
    "        \n",
    "        # Convert data to numeric arrays\n",
    "        self.clinical_data = pd.get_dummies(self.clinical_data, drop_first=True).to_numpy(dtype=np.float32)\n",
    "        self.cna_data = self.cna_data.to_numpy(dtype=np.float32)\n",
    "        self.mrna_data = self.mrna_data.to_numpy(dtype=np.float32)\n",
    "        \n",
    "        # Ensure labels are aligned and converted to numeric arrays\n",
    "        self.labels = self.labels[\"SURVIVAL_BINARY\"].to_numpy(dtype=np.float32)  # Use only the label column\n",
    "\n",
    "        print(\"Clinical data shape:\", self.clinical_data.shape)\n",
    "        print(\"CNA data shape:\", self.cna_data.shape)\n",
    "        print(\"mRNA data shape:\", self.mrna_data.shape)\n",
    "        print(\"Labels shape:\", self.labels.shape)       \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        clinical = torch.tensor(self.clinical_data[idx], dtype=torch.float32)\n",
    "        cna = torch.tensor(self.cna_data[idx], dtype=torch.float32)\n",
    "        mrna = torch.tensor(self.mrna_data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return clinical, cna, mrna, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical data shape: (1980, 196)\n",
      "CNA data shape: (1980, 22544)\n",
      "mRNA data shape: (1980, 20603)\n",
      "Labels shape: (1980,)\n",
      "Clinical shape: torch.Size([32, 196])\n",
      "CNA shape: torch.Size([32, 22544])\n",
      "mRNA shape: torch.Size([32, 20603])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Paths to preprocessed files\n",
    "clinical_path = \"brca_metabric/dataset/clinical_data.csv\"\n",
    "cna_path = \"brca_metabric/dataset/cna_data.csv\"\n",
    "mrna_path = \"brca_metabric/dataset/mrna_zscores.csv\"\n",
    "labels_path = \"brca_metabric/dataset/labels.csv\"\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset = BreastCancerDataset(clinical_path, cna_path, mrna_path, labels_path)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Test the DataLoader\n",
    "for clinical, cna, mrna, label in dataloader:\n",
    "    print(f\"Clinical shape: {clinical.shape}\")\n",
    "    print(f\"CNA shape: {cna.shape}\")\n",
    "    print(f\"mRNA shape: {mrna.shape}\")\n",
    "    print(f\"Labels shape: {label.shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical data NaNs: False\n",
      "CNA data NaNs: True\n",
      "mRNA data NaNs: True\n",
      "Labels NaNs: False\n",
      "Training samples: 1683\n",
      "Testing samples: 297\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation and testing sets and remove NaNs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Check and remove NaNs from dataset\n",
    "print(\"Clinical data NaNs:\", np.any(np.isnan(dataset.clinical_data)))\n",
    "print(\"CNA data NaNs:\", np.any(np.isnan(dataset.cna_data)))\n",
    "print(\"mRNA data NaNs:\", np.any(np.isnan(dataset.mrna_data)))\n",
    "print(\"Labels NaNs:\", np.any(np.isnan(dataset.labels)))\n",
    "\n",
    "# Remove columns with NaNs in CNA and mRNA data\n",
    "cna_nan_columns = np.isnan(dataset.cna_data).any(axis=0)\n",
    "dataset.cna_data = dataset.cna_data[:, ~cna_nan_columns]\n",
    "mrna_nan_columns = np.isnan(dataset.mrna_data).any(axis=0)\n",
    "dataset.mrna_data = dataset.mrna_data[:, ~mrna_nan_columns]\n",
    "\n",
    "# Split dataset into train (70%), validation (10%), and test (20%) sets\n",
    "dataset_size = len(dataset)\n",
    "indices = np.arange(dataset_size)\n",
    "\n",
    "# Perform the first split to separate training data\n",
    "train_indices, test_indices, train_labels, temp_labels = train_test_split(\n",
    "    indices, dataset.labels, test_size=0.15, random_state=42, stratify=dataset.labels\n",
    ")\n",
    "\n",
    "# Perform the second split to divide validation and test data\n",
    "# val_indices, test_indices = train_test_split(\n",
    "#     test_indices, test_size=0.5, random_state=42, stratify=temp_labels\n",
    "# )\n",
    "\n",
    "# Create subsets for each split\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "# val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders for each subset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "# print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture for each modality\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ClinicalModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ClinicalModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class CNAModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(CNAModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class mRNAModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(mRNAModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the combined model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, clinical_dim, cna_dim, mrna_dim, hidden_dim, output_dim):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        # Sub-models for each modality\n",
    "        self.clinical_model = ClinicalModel(clinical_dim, hidden_dim)\n",
    "        self.cna_model = CNAModel(cna_dim, hidden_dim)\n",
    "        self.mrna_model = mRNAModel(mrna_dim, hidden_dim)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3*hidden_dim, hidden_dim),  # Concatenate outputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()  # Binary classification\n",
    "        )\n",
    "        \n",
    "    def forward(self, clinical, cna, mrna):\n",
    "        # Get embeddings from each modality\n",
    "        clinical_emb = self.clinical_model(clinical)\n",
    "        cna_emb = self.cna_model(cna)\n",
    "        mrna_emb = self.mrna_model(mrna)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        combined_emb = torch.cat((clinical_emb, cna_emb, mrna_emb), dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.classifier(combined_emb)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Train Loss: 0.5760, Train Accuracy: 0.7213 - Val Loss: 0.5162, Val Accuracy: 0.7508\n",
      "Epoch [2/100] - Train Loss: 0.4727, Train Accuracy: 0.7748 - Val Loss: 0.5041, Val Accuracy: 0.7542\n",
      "Epoch [3/100] - Train Loss: 0.3581, Train Accuracy: 0.8526 - Val Loss: 0.5133, Val Accuracy: 0.7542\n",
      "Epoch [4/100] - Train Loss: 0.2042, Train Accuracy: 0.9352 - Val Loss: 0.5781, Val Accuracy: 0.7643\n",
      "Epoch [5/100] - Train Loss: 0.0635, Train Accuracy: 0.9905 - Val Loss: 0.7023, Val Accuracy: 0.7576\n",
      "Epoch [6/100] - Train Loss: 0.0152, Train Accuracy: 1.0000 - Val Loss: 0.8007, Val Accuracy: 0.7407\n",
      "Epoch [7/100] - Train Loss: 0.0040, Train Accuracy: 1.0000 - Val Loss: 0.8800, Val Accuracy: 0.7340\n",
      "Epoch [8/100] - Train Loss: 0.0020, Train Accuracy: 1.0000 - Val Loss: 0.9311, Val Accuracy: 0.7374\n",
      "Epoch [9/100] - Train Loss: 0.0012, Train Accuracy: 1.0000 - Val Loss: 0.9861, Val Accuracy: 0.7306\n",
      "Epoch [10/100] - Train Loss: 0.0008, Train Accuracy: 1.0000 - Val Loss: 1.0453, Val Accuracy: 0.7407\n",
      "Epoch [11/100] - Train Loss: 0.0006, Train Accuracy: 1.0000 - Val Loss: 1.0613, Val Accuracy: 0.7340\n",
      "Epoch [12/100] - Train Loss: 0.0004, Train Accuracy: 1.0000 - Val Loss: 1.1002, Val Accuracy: 0.7441\n",
      "Early stopping at epoch 12. Best validation loss: 0.5041\n",
      "Best model weights restored.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer and train the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hyperparameters\n",
    "clinical_dim = dataset.clinical_data.shape[1]\n",
    "cna_dim = dataset.cna_data.shape[1]\n",
    "mrna_dim = dataset.mrna_data.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = CombinedModel(clinical_dim, cna_dim, mrna_dim, hidden_dim, output_dim)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10\n",
    "best_val_loss = np.inf\n",
    "no_improve_epochs = 0\n",
    "best_model_weights = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_predictions = []\n",
    "\n",
    "    # Training phase\n",
    "    for clinical, cna, mrna, labels in train_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(clinical, cna, mrna).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Save predictions and true labels for accuracy calculation\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        all_train_labels.extend(labels.numpy())\n",
    "        all_train_predictions.extend(predictions.numpy())\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_predictions)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_labels = []\n",
    "    all_val_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for clinical, cna, mrna, labels in test_dataloader:\n",
    "            outputs = model(clinical, cna, mrna).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            all_val_labels.extend(labels.numpy())\n",
    "            all_val_predictions.extend(predictions.numpy())\n",
    "\n",
    "    val_loss /= len(test_dataloader)\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_predictions)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}]\"\n",
    "        f\" - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\"\n",
    "        f\" - Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check for improvement in validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "        best_model_weights = model.state_dict()  # Save best weights\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}. Best validation loss: {best_val_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "# Restore the best model weights after early stopping\n",
    "if best_model_weights:\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    print(\"Best model weights restored.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1002\n",
      "Accuracy: 0.7441\n",
      "F1 Score: 0.8410\n",
      "AUC: 0.5858\n",
      "AUPRC: 0.7845\n",
      "Precision: 0.7882\n",
      "Recall: 0.9013\n",
      "Specificity: 0.2703\n",
      "MCC: 0.2130\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for clinical, cna, mrna, labels in test_dataloader:\n",
    "        # clinical, cna, mrna, labels = clinical.to('cuda'), cna.to('cuda'), mrna.to('cuda'), labels.to('cuda')       \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(clinical, cna, mrna).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Save predictions for evaluation\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_dataloader):.4f}\")\n",
    "\n",
    "calculate_metrics(all_labels, all_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
