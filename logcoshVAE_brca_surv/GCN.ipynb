{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced shapes of modalities:\n",
      "Clinical: (1592, 19)\n",
      "CNV: (1592, 500)\n",
      "DNA: (1592, 500)\n",
      "miRNA: (1592, 500)\n",
      "mRNA: (1592, 500)\n",
      "WSI: (1592, 800)\n",
      "Labels: (1592,)\n",
      "\n",
      "Class distribution after balancing:\n",
      "Positive samples: 796\n",
      "Negative samples: 796\n"
     ]
    }
   ],
   "source": [
    "# load 6 modalites data \n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    cln_data = pd.read_csv('data/raw_features_cln.csv')\n",
    "    cnv_data = pd.read_csv('data/raw_features_cnv.csv')\n",
    "    dna_data = pd.read_csv('data/raw_features_dna.csv')\n",
    "    mir_data = pd.read_csv('data/raw_features_mir.csv')\n",
    "    mrna_data = pd.read_csv('data/raw_features_mrna.csv')\n",
    "    wsi_data = pd.read_csv('data/raw_features_wsi.csv')\n",
    "\n",
    "    # keep data where all modalities are present based on patient id\n",
    "    patient_ids = set(cln_data['submitter_id.samples'])\n",
    "    patient_ids = patient_ids.intersection(set(cnv_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(dna_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(mir_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(mrna_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(wsi_data['submitter_id.samples']))\n",
    "\n",
    "    cln_data = cln_data[cln_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    cnv_data = cnv_data[cnv_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    dna_data = dna_data[dna_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    mir_data = mir_data[mir_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    mrna_data = mrna_data[mrna_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    wsi_data = wsi_data[wsi_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "\n",
    "    # sort data by patient id\n",
    "    cln_data = cln_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    cnv_data = cnv_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    dna_data = dna_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    mir_data = mir_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    mrna_data = mrna_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    wsi_data = wsi_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "\n",
    "    # make sure the labels column match for all modalities\n",
    "    cln_labels = cln_data['label_cln']\n",
    "    cnv_labels = cnv_data['label_cnv']\n",
    "    dna_labels = dna_data['label_dna']\n",
    "    mir_labels = mir_data['label_mir']\n",
    "    mrna_labels = mrna_data['label_mrna']\n",
    "    wsi_labels = wsi_data['label_wsi']\n",
    "\n",
    "    assert np.all(cln_labels == cnv_labels), \"Labels mismatch between clinical and CNV data\"\n",
    "    assert np.all(cln_labels == dna_labels), \"Labels mismatch between clinical and DNA data\"\n",
    "    assert np.all(cln_labels == mir_labels), \"Labels mismatch between clinical and miRNA data\"\n",
    "    assert np.all(cln_labels == mrna_labels), \"Labels mismatch between clinical and mRNA data\"\n",
    "    # assert np.all(cln_labels == wsi_labels), \"Labels mismatch between clinical and WSI data\"\n",
    "\n",
    "    # drop labels column and patient id column\n",
    "    cln_data = cln_data.drop(columns=['label_cln', 'submitter_id.samples'])\n",
    "    cnv_data = cnv_data.drop(columns=['label_cnv', 'submitter_id.samples'])\n",
    "    dna_data = dna_data.drop(columns=['label_dna', 'submitter_id.samples'])\n",
    "    mir_data = mir_data.drop(columns=['label_mir', 'submitter_id.samples'])\n",
    "    mrna_data = mrna_data.drop(columns=['label_mrna', 'submitter_id.samples'])\n",
    "    wsi_data = wsi_data.drop(columns=['label_wsi', 'submitter_id.samples'])\n",
    "\n",
    "    # normalize data\n",
    "    stdscalar = StandardScaler()\n",
    "    cln_data = stdscalar.fit_transform(cln_data)\n",
    "    cnv_data = stdscalar.fit_transform(cnv_data)\n",
    "    dna_data = stdscalar.fit_transform(dna_data)\n",
    "    mir_data = stdscalar.fit_transform(mir_data)\n",
    "    mrna_data = stdscalar.fit_transform(mrna_data)\n",
    "    wsi_data = stdscalar.fit_transform(wsi_data)\n",
    "\n",
    "    return cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data, cln_labels\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def balance_modality_data(features_list, labels, method='SMOTE'):\n",
    "    \"\"\"\n",
    "    Balances the dataset for each modality separately.\n",
    "    \n",
    "    Parameters:\n",
    "    - features_list: List of feature matrices, one for each modality.\n",
    "    - labels: Binary labels (numpy array or Series).\n",
    "    - method: Balancing method ('SMOTE' supported here).\n",
    "    \n",
    "    Returns:\n",
    "    - Separate balanced feature matrices for each modality.\n",
    "    - Balanced labels (same across all modalities).\n",
    "    \"\"\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "    balanced_features_list = []\n",
    "    \n",
    "    for modality_features in features_list:\n",
    "        # Balance the current modality's features and labels\n",
    "        balanced_modality_features, balanced_labels = smote.fit_resample(modality_features, labels)\n",
    "        balanced_features_list.append(balanced_modality_features)\n",
    "    \n",
    "    # Unpack balanced features into separate variables and return them\n",
    "    return (*balanced_features_list, balanced_labels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the data\n",
    "    cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data, labels = load_data()\n",
    "    \n",
    "    # List of modalities\n",
    "    features_list = [cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data]\n",
    "    \n",
    "    # Balance the modalities and unpack them\n",
    "    balanced_cln_data, balanced_cnv_data, balanced_dna_data, balanced_mir_data, balanced_mrna_data, balanced_wsi_data, balanced_labels = balance_modality_data(features_list, labels, method='SMOTE')\n",
    "    \n",
    "    # Print shapes\n",
    "    print(\"\\nBalanced shapes of modalities:\")\n",
    "    print(f\"Clinical: {balanced_cln_data.shape}\")\n",
    "    print(f\"CNV: {balanced_cnv_data.shape}\")\n",
    "    print(f\"DNA: {balanced_dna_data.shape}\")\n",
    "    print(f\"miRNA: {balanced_mir_data.shape}\")\n",
    "    print(f\"mRNA: {balanced_mrna_data.shape}\")\n",
    "    print(f\"WSI: {balanced_wsi_data.shape}\")\n",
    "    print(f\"Labels: {balanced_labels.shape}\")\n",
    "\n",
    "    # Class distribution\n",
    "    print(\"\\nClass distribution after balancing:\")\n",
    "    print(f\"Positive samples: {np.sum(balanced_labels == 1)}\")\n",
    "    print(f\"Negative samples: {np.sum(balanced_labels == 0)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a MultimodalDataset class if not already defined\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, *modalities, labels):\n",
    "        self.modalities = modalities\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return tuple(modality[idx] for modality in self.modalities) + (self.labels[idx],)\n",
    "\n",
    "\n",
    "def load_and_split_data(modalities, labels, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets, and balances the test set.\n",
    "    \"\"\"\n",
    "    # Split the data into train and test sets\n",
    "    train_modalities, test_modalities = [], []\n",
    "    for modality in modalities:\n",
    "        train, test = train_test_split(modality, test_size=test_size, random_state=random_state)\n",
    "        train_modalities.append(train)\n",
    "        test_modalities.append(test)\n",
    "\n",
    "    labels_train, labels_test = train_test_split(labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return train_modalities, test_modalities, labels_train, labels_test\n",
    "\n",
    "# Function to convert data to tensors\n",
    "def convert_to_tensors(data):\n",
    "    return [torch.tensor(modality, dtype=torch.float32) for modality in data]\n",
    "\n",
    "# Main code\n",
    "def get_train_test_loader():\n",
    "    # Load the data\n",
    "    cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data, labels = load_data()\n",
    "    modalities = [cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data]\n",
    "    # cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data, labels = balance_modality_data(modalities, labels)\n",
    "    modalities = [cln_data, cnv_data, mrna_data]\n",
    "    # Split data\n",
    "    train_modalities, test_modalities, labels_train, labels_test = load_and_split_data(modalities, labels)\n",
    "\n",
    "    # Convert data to tensors\n",
    "    train_tensors = convert_to_tensors(train_modalities)\n",
    "    test_tensors = convert_to_tensors(test_modalities)\n",
    "    labels_train = torch.tensor(labels_train, dtype=torch.long)\n",
    "    labels_test = torch.tensor(labels_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = MultimodalDataset(*train_tensors, labels=labels_train)\n",
    "    test_dataset = MultimodalDataset(*test_tensors, labels=labels_test)\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_modalities, test_modalities, labels_train, labels_test\n",
    "\n",
    "# Run the main function\n",
    "train_modalities, test_modalities, labels_train, labels_test = get_train_test_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Step 1: Graph Creation\n",
    "def create_graph(data, threshold):\n",
    "    \"\"\"\n",
    "    Create a graph from the data where nodes represent patients and edges \n",
    "    are created based on a Pearson correlation threshold.\n",
    "    \n",
    "    Args:\n",
    "    - data (numpy array): Feature matrix of shape (num_patients, num_features).\n",
    "    - threshold (float): Correlation threshold for edge creation.\n",
    "    \n",
    "    Returns:\n",
    "    - PyTorch Geometric Data object representing the graph.\n",
    "    \"\"\"\n",
    "    num_patients = data.shape[0]\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    # Add nodes\n",
    "    graph.add_nodes_from(range(num_patients))\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = np.corrcoef(data)\n",
    "\n",
    "    # Add edges based on threshold\n",
    "    for i in range(num_patients):\n",
    "        for j in range(i + 1, num_patients):\n",
    "            if corr_matrix[i, j] > threshold:\n",
    "                graph.add_edge(i, j)\n",
    "\n",
    "    # Convert to PyTorch Geometric Data format\n",
    "    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    print(f'Number of nodes: {num_patients}, Number of edges: {edge_index.size(1)}')\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 828, Number of edges: 301\n",
      "Number of nodes: 828, Number of edges: 12342\n",
      "Number of nodes: 828, Number of edges: 4449\n"
     ]
    }
   ],
   "source": [
    "graphs = [create_graph(data, threshold) for data, threshold in zip(train_modalities, thresholds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1273, Number of edges: 1539\n",
      "Number of nodes: 1273, Number of edges: 9569\n",
      "Number of nodes: 1273, Number of edges: 1066\n",
      "Training GCN model 0...\n",
      "Epoch: 0, Loss: 7.191842555999756\n",
      "Epoch: 1, Loss: 5.279943943023682\n",
      "Epoch: 2, Loss: 3.8726251125335693\n",
      "Epoch: 3, Loss: 2.8523590564727783\n",
      "Epoch: 4, Loss: 2.1233880519866943\n",
      "Epoch: 5, Loss: 1.6098545789718628\n",
      "Epoch: 6, Loss: 1.2529451847076416\n",
      "Epoch: 7, Loss: 1.005657434463501\n",
      "Epoch: 8, Loss: 0.8345305919647217\n",
      "Epoch: 9, Loss: 0.7149323225021362\n",
      "Training GCN model 1...\n",
      "Epoch: 0, Loss: 14.431365013122559\n",
      "Epoch: 1, Loss: 85.24732971191406\n",
      "Epoch: 2, Loss: 33.933998107910156\n",
      "Epoch: 3, Loss: 34.67918014526367\n",
      "Epoch: 4, Loss: 29.4047908782959\n",
      "Epoch: 5, Loss: 20.147443771362305\n",
      "Epoch: 6, Loss: 16.933536529541016\n",
      "Epoch: 7, Loss: 14.673105239868164\n",
      "Epoch: 8, Loss: 11.570744514465332\n",
      "Epoch: 9, Loss: 9.765456199645996\n",
      "Training GCN model 2...\n",
      "Epoch: 0, Loss: 16.304256439208984\n",
      "Epoch: 1, Loss: 45.40164566040039\n",
      "Epoch: 2, Loss: 17.823678970336914\n",
      "Epoch: 3, Loss: 14.229995727539062\n",
      "Epoch: 4, Loss: 12.178971290588379\n",
      "Epoch: 5, Loss: 10.868371963500977\n",
      "Epoch: 6, Loss: 9.064963340759277\n",
      "Epoch: 7, Loss: 7.436390399932861\n",
      "Epoch: 8, Loss: 6.450118064880371\n",
      "Epoch: 9, Loss: 5.46099853515625\n",
      "Training classifier...\n",
      "Epoch: 0, Loss: 0.70387864112854\n",
      "Epoch: 1, Loss: 0.6852903366088867\n",
      "Epoch: 2, Loss: 0.6777523756027222\n",
      "Epoch: 3, Loss: 0.6699482202529907\n",
      "Epoch: 4, Loss: 0.659881591796875\n",
      "Epoch: 5, Loss: 0.6496015787124634\n",
      "Epoch: 6, Loss: 0.6407246589660645\n",
      "Epoch: 7, Loss: 0.632254958152771\n",
      "Epoch: 8, Loss: 0.6222429871559143\n",
      "Epoch: 9, Loss: 0.6109674572944641\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from itertools import combinations\n",
    "\n",
    "# Step 2: GCN Model\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Step 3: Sampling Pairs\n",
    "def sample_pairs(labels):\n",
    "    \"\"\"\n",
    "    Generate positive and negative pairs from the labels.\n",
    "\n",
    "    Args:\n",
    "    - labels (torch.Tensor): Labels of the nodes.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple[int, int]]: Positive and negative pairs (indices of nodes).\n",
    "    \"\"\"\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    for i, j in combinations(range(len(labels)), 2):\n",
    "        if labels[i] == labels[j]:\n",
    "            positive_pairs.append((i, j))\n",
    "        else:\n",
    "            negative_pairs.append((i, j))\n",
    "    return positive_pairs, negative_pairs\n",
    "\n",
    "# Step 4: Contrastive Loss\n",
    "def pairwise_contrastive_loss(embeddings, positive_pairs, negative_pairs, margin=1.0):\n",
    "    \"\"\"\n",
    "    Compute contrastive loss using sampled positive and negative pairs.\n",
    "\n",
    "    Args:\n",
    "    - embeddings (torch.Tensor): Embedding matrix.\n",
    "    - positive_pairs (List[Tuple[int, int]]): Positive pairs.\n",
    "    - negative_pairs (List[Tuple[int, int]]): Negative pairs.\n",
    "    - margin (float): Margin for dissimilar embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Contrastive loss.\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "\n",
    "    # Positive pairs\n",
    "    for i, j in positive_pairs:\n",
    "        dist = torch.norm(embeddings[i] - embeddings[j])\n",
    "        loss += dist ** 2  # Pull closer\n",
    "\n",
    "    # Negative pairs\n",
    "    for i, j in negative_pairs:\n",
    "        dist = torch.norm(embeddings[i] - embeddings[j])\n",
    "        loss += torch.clamp(margin - dist, min=0) ** 2  # Push apart\n",
    "\n",
    "    return loss / (len(positive_pairs) + len(negative_pairs))\n",
    "\n",
    "# Step 5: Classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Example thresholds and data\n",
    "thresholds = [0.95, 0.9, 0.8]\n",
    "\n",
    "# Create graphs for each modality\n",
    "graphs = [create_graph(data, threshold) for data, threshold in zip(train_modalities, thresholds)]\n",
    "\n",
    "# Initialize GCN models for each modality\n",
    "gcn_models = []\n",
    "cln_model = GCNEncoder(input_dim=balanced_cln_data.shape[1], hidden_dim=32, output_dim=16)\n",
    "cnv_model = GCNEncoder(input_dim=balanced_cnv_data.shape[1], hidden_dim=32, output_dim=16)\n",
    "dna_model = GCNEncoder(input_dim=balanced_dna_data.shape[1], hidden_dim=32, output_dim=16)\n",
    "mir_model = GCNEncoder(input_dim=balanced_mir_data.shape[1], hidden_dim=32, output_dim=16)\n",
    "mrna_model = GCNEncoder(input_dim=balanced_mrna_data.shape[1], hidden_dim=32, output_dim=16)\n",
    "wsi_model = GCNEncoder(input_dim=balanced_wsi_data.shape[1], hidden_dim=32, output_dim=16)\n",
    "gcn_models = [cln_model, cnv_model, mrna_model]\n",
    "optimizers = [torch.optim.Adam(model.parameters(), lr=0.01) for model in gcn_models]\n",
    "\n",
    "# Training GCNs\n",
    "epochs = 10\n",
    "for i, (model, graph, optimizer) in enumerate(zip(gcn_models, graphs, optimizers)):\n",
    "    print(f'Training GCN model {i}...')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings = model(graph.x, graph.edge_index)\n",
    "\n",
    "        # Sample pairs and compute loss\n",
    "        positive_pairs, negative_pairs = sample_pairs(labels_train)\n",
    "        loss = pairwise_contrastive_loss(embeddings, positive_pairs, negative_pairs)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Concatenate embeddings from all modalities\n",
    "all_embeddings = []\n",
    "for model, graph in zip(gcn_models, graphs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(graph.x, graph.edge_index)\n",
    "        all_embeddings.append(embeddings)\n",
    "concatenated_embeddings = torch.cat(all_embeddings, dim=1)\n",
    "\n",
    "# Initialize and train the classifier\n",
    "classifier = Classifier(input_dim=concatenated_embeddings.size(1), hidden_dim=32, num_classes=2)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Training classifier...\")\n",
    "for epoch in range(epochs):\n",
    "    classifier.train()\n",
    "    classifier_optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass and compute loss\n",
    "    logits = classifier(concatenated_embeddings)\n",
    "    classification_loss = F.cross_entropy(logits, labels_train)\n",
    "    classification_loss.backward()\n",
    "    classifier_optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {classification_loss.item()}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 207, Number of edges: 41\n",
      "Number of nodes: 207, Number of edges: 538\n",
      "Number of nodes: 207, Number of edges: 574\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5519\n",
      "Test F1 Score: 0.5836\n",
      "Test AUC: 0.6277\n",
      "Test Specificity: 0.6583\n",
      "Test Recall: 0.5183\n",
      "Test Precision: 0.8274\n",
      "Test MCC: 0.1511\n",
      "Test AUPRC: 0.8337\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.66      0.41       199\n",
      "           1       0.83      0.52      0.64       629\n",
      "\n",
      "    accuracy                           0.55       828\n",
      "   macro avg       0.56      0.59      0.53       828\n",
      "weighted avg       0.70      0.55      0.58       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef, recall_score, precision_score, average_precision_score\n",
    "import seaborn as sns\n",
    "thresholds = [0.95, 0.7, 0.5, 0.5, 0.2]\n",
    "# Create graphs for the test modalities\n",
    "test_graphs = [create_graph(data, threshold) for data, threshold in zip(test_modalities, thresholds)]\n",
    "# Generate embeddings for test graphs using trained GCN models\n",
    "test_embeddings_list = []\n",
    "for model, test_graph in zip(gcn_models, graphs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(test_graph.x, test_graph.edge_index)\n",
    "        test_embeddings_list.append(embeddings)\n",
    "\n",
    "# Concatenate embeddings across modalities\n",
    "concatenated_test_embeddings = torch.cat(test_embeddings_list, dim=1)\n",
    "# Evaluate the classifier on the test set\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = classifier(concatenated_test_embeddings)\n",
    "    test_prob = F.softmax(test_logits, dim=1)\n",
    "    test_pred = (test_prob[:, 1] > 0.5).long()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Convert tensors to numpy arrays for metrics calculation\n",
    "labels_test_np = labels_train.cpu().numpy()\n",
    "test_pred_np = test_pred.cpu().numpy()\n",
    "test_prob_np = test_prob.cpu().numpy()\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(labels_test_np, test_pred_np)\n",
    "f1 = f1_score(labels_test_np, test_pred_np, average='weighted')\n",
    "auc = roc_auc_score(labels_test_np, test_prob_np[:, 1])\n",
    "cm = confusion_matrix(labels_test_np, test_pred_np)\n",
    "specificity = cm[0, 0] / cm[0, :].sum()\n",
    "recall = recall_score(labels_test_np, test_pred_np)\n",
    "precision = precision_score(labels_test_np, test_pred_np)\n",
    "mcc = matthews_corrcoef(labels_test_np, test_pred_np)\n",
    "auprc = average_precision_score(labels_test_np, test_prob_np[:, 1])\n",
    "classification_rep = classification_report(labels_test_np, test_pred_np)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 16})\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test Specificity: {specificity:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test MCC: {mcc:.4f}\")\n",
    "print(f\"Test AUPRC: {auprc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
