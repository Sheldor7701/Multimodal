{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced shapes of modalities:\n",
      "(1592, 19)\n",
      "(1592, 500)\n",
      "(1592, 500)\n",
      "(1592, 500)\n",
      "(1592, 500)\n",
      "(1592, 800)\n",
      "Labels: (1592,)\n",
      "\n",
      "Class distribution after balancing:\n",
      "Positive samples: 796\n",
      "Negative samples: 796\n"
     ]
    }
   ],
   "source": [
    "# load 6 modalites data \n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    cln_data = pd.read_csv('data/raw_features_cln.csv')\n",
    "    cnv_data = pd.read_csv('data/raw_features_cnv.csv')\n",
    "    dna_data = pd.read_csv('data/raw_features_dna.csv')\n",
    "    mir_data = pd.read_csv('data/raw_features_mir.csv')\n",
    "    mrna_data = pd.read_csv('data/raw_features_mrna.csv')\n",
    "    wsi_data = pd.read_csv('data/raw_features_wsi.csv')\n",
    "\n",
    "    # keep data where all modalities are present based on patient id\n",
    "    patient_ids = set(cln_data['submitter_id.samples'])\n",
    "    patient_ids = patient_ids.intersection(set(cnv_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(dna_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(mir_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(mrna_data['submitter_id.samples']))\n",
    "    patient_ids = patient_ids.intersection(set(wsi_data['submitter_id.samples']))\n",
    "\n",
    "    cln_data = cln_data[cln_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    cnv_data = cnv_data[cnv_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    dna_data = dna_data[dna_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    mir_data = mir_data[mir_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    mrna_data = mrna_data[mrna_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "    wsi_data = wsi_data[wsi_data['submitter_id.samples'].isin(patient_ids)].reset_index(drop=True)\n",
    "\n",
    "    # sort data by patient id\n",
    "    cln_data = cln_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    cnv_data = cnv_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    dna_data = dna_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    mir_data = mir_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    mrna_data = mrna_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "    wsi_data = wsi_data.sort_values('submitter_id.samples').reset_index(drop=True)\n",
    "\n",
    "    # make sure the labels column match for all modalities\n",
    "    cln_labels = cln_data['label_cln']\n",
    "    cnv_labels = cnv_data['label_cnv']\n",
    "    dna_labels = dna_data['label_dna']\n",
    "    mir_labels = mir_data['label_mir']\n",
    "    mrna_labels = mrna_data['label_mrna']\n",
    "    wsi_labels = wsi_data['label_wsi']\n",
    "\n",
    "    assert np.all(cln_labels == cnv_labels), \"Labels mismatch between clinical and CNV data\"\n",
    "    assert np.all(cln_labels == dna_labels), \"Labels mismatch between clinical and DNA data\"\n",
    "    assert np.all(cln_labels == mir_labels), \"Labels mismatch between clinical and miRNA data\"\n",
    "    assert np.all(cln_labels == mrna_labels), \"Labels mismatch between clinical and mRNA data\"\n",
    "    # assert np.all(cln_labels == wsi_labels), \"Labels mismatch between clinical and WSI data\"\n",
    "\n",
    "    # drop labels column and patient id column\n",
    "    cln_data = cln_data.drop(columns=['label_cln', 'submitter_id.samples'])\n",
    "    cnv_data = cnv_data.drop(columns=['label_cnv', 'submitter_id.samples'])\n",
    "    dna_data = dna_data.drop(columns=['label_dna', 'submitter_id.samples'])\n",
    "    mir_data = mir_data.drop(columns=['label_mir', 'submitter_id.samples'])\n",
    "    mrna_data = mrna_data.drop(columns=['label_mrna', 'submitter_id.samples'])\n",
    "    wsi_data = wsi_data.drop(columns=['label_wsi', 'submitter_id.samples'])\n",
    "\n",
    "    # normalize data\n",
    "    stdscalar = StandardScaler()\n",
    "    cln_data = stdscalar.fit_transform(cln_data)\n",
    "    cnv_data = stdscalar.fit_transform(cnv_data)\n",
    "    dna_data = stdscalar.fit_transform(dna_data)\n",
    "    mir_data = stdscalar.fit_transform(mir_data)\n",
    "    mrna_data = stdscalar.fit_transform(mrna_data)\n",
    "    wsi_data = stdscalar.fit_transform(wsi_data)\n",
    "\n",
    "    return cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data, cln_labels\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def balance_modality_data(features_list, labels, method='SMOTE'):\n",
    "    \"\"\"\n",
    "    Balances the dataset for each modality separately.\n",
    "    \n",
    "    Parameters:\n",
    "    - features_list: List of feature matrices, one for each modality.\n",
    "    - labels: Binary labels (numpy array or Series).\n",
    "    - method: Balancing method ('SMOTE' supported here).\n",
    "    \n",
    "    Returns:\n",
    "    - Separate balanced feature matrices for each modality.\n",
    "    - Balanced labels (same across all modalities).\n",
    "    \"\"\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "    balanced_features_list = []\n",
    "    \n",
    "    for modality_features in features_list:\n",
    "        # Balance the current modality's features and labels\n",
    "        balanced_modality_features, balanced_labels = smote.fit_resample(modality_features, labels)\n",
    "        balanced_features_list.append(balanced_modality_features)\n",
    "    \n",
    "    # Unpack balanced features into separate variables and return them\n",
    "    return (balanced_features_list, balanced_labels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the data\n",
    "    cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data, labels = load_data()\n",
    "    \n",
    "    # List of modalities\n",
    "    features_list = [cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data]\n",
    "    \n",
    "    # Balance the modalities and unpack them\n",
    "    balanced_data, balanced_labels = balance_modality_data(features_list, labels, method='SMOTE')\n",
    "    \n",
    "    # Print shapes\n",
    "    print(\"\\nBalanced shapes of modalities:\")\n",
    "    for data in balanced_data:\n",
    "        print(data.shape)\n",
    "    print(f\"Labels: {balanced_labels.shape}\")\n",
    "\n",
    "    # Class distribution\n",
    "    print(\"\\nClass distribution after balancing:\")\n",
    "    print(f\"Positive samples: {np.sum(balanced_labels == 1)}\")\n",
    "    print(f\"Negative samples: {np.sum(balanced_labels == 0)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a MultimodalDataset class if not already defined\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, *modalities, labels):\n",
    "        self.modalities = modalities\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return tuple(modality[idx] for modality in self.modalities) + (self.labels[idx],)\n",
    "\n",
    "\n",
    "def load_and_split_data(modalities, labels, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets, and balances the test set.\n",
    "    \"\"\"\n",
    "    # Split the data into train and test sets\n",
    "    train_modalities, test_modalities = [], []\n",
    "    for modality in modalities:\n",
    "        train, test = train_test_split(modality, test_size=test_size, random_state=random_state)\n",
    "        train_modalities.append(train)\n",
    "        test_modalities.append(test)\n",
    "\n",
    "    labels_train, labels_test = train_test_split(labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return train_modalities, test_modalities, labels_train, labels_test\n",
    "\n",
    "# Function to convert data to tensors\n",
    "def convert_to_tensors(data):\n",
    "    return [torch.tensor(modality, dtype=torch.float32) for modality in data]\n",
    "\n",
    "# Main code\n",
    "def get_train_test_loader():\n",
    "    # Load the data\n",
    "    cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data, labels = load_data()\n",
    "    modalities = [mir_data, mrna_data, wsi_data]\n",
    "    balanced_data, labels = balance_modality_data(modalities, labels)\n",
    "    modalities = []\n",
    "    for data in balanced_data:\n",
    "        modalities.append(data)\n",
    "    # modalities = [cln_data, cnv_data, dna_data, mir_data, mrna_data, wsi_data]\n",
    "    # Split data\n",
    "    train_modalities, test_modalities, labels_train, labels_test = load_and_split_data(modalities, labels)\n",
    "\n",
    "    # train_modalities, labels_train = balance_modality_data(train_modalities, labels_train)\n",
    "    # test_modalities, labels_test = balance_modality_data(test_modalities, labels_test)\n",
    "\n",
    "    # Convert data to tensors\n",
    "    train_tensors = convert_to_tensors(train_modalities)\n",
    "    test_tensors = convert_to_tensors(test_modalities)\n",
    "    labels_train = torch.tensor(labels_train, dtype=torch.long)\n",
    "    labels_test = torch.tensor(labels_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = MultimodalDataset(*train_tensors, labels=labels_train)\n",
    "    test_dataset = MultimodalDataset(*test_tensors, labels=labels_test)\n",
    "\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_modalities, test_modalities, labels_train, labels_test, train_loader, test_loader\n",
    "\n",
    "# Run the main function\n",
    "train_modalities, test_modalities, labels_train, labels_test,_,_ = get_train_test_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Step 1: Graph Creation\n",
    "def create_graph(data, threshold):\n",
    "    \"\"\"\n",
    "    Create a graph from the data where nodes represent patients and edges \n",
    "    are created based on a Pearson correlation threshold.\n",
    "    \n",
    "    Args:\n",
    "    - data (numpy array): Feature matrix of shape (num_patients, num_features).\n",
    "    - threshold (float): Correlation threshold for edge creation.\n",
    "    \n",
    "    Returns:\n",
    "    - PyTorch Geometric Data object representing the graph.\n",
    "    \"\"\"\n",
    "    num_patients = data.shape[0]\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    # Add nodes\n",
    "    graph.add_nodes_from(range(num_patients))\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = np.corrcoef(data)\n",
    "\n",
    "    # Add edges based on threshold\n",
    "    for i in range(num_patients):\n",
    "        for j in range(i + 1, num_patients):\n",
    "            if corr_matrix[i, j] > threshold:\n",
    "                graph.add_edge(i, j)\n",
    "\n",
    "    # Convert to PyTorch Geometric Data format\n",
    "    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    print(f'Number of nodes: {num_patients}, Number of edges: {edge_index.size(1)}')\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1273, Number of edges: 924\n",
      "Number of nodes: 1273, Number of edges: 1066\n",
      "Number of nodes: 1273, Number of edges: 1090\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n",
    "graphs = [create_graph(data, threshold) for data, threshold in zip(train_modalities, thresholds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1273, Number of edges: 924\n",
      "Number of nodes: 1273, Number of edges: 1066\n",
      "Number of nodes: 1273, Number of edges: 1090\n",
      "Training GCN model 0...\n",
      "Epoch: 0, Loss: 16.368896484375\n",
      "Epoch: 1, Loss: 28.593276977539062\n",
      "Epoch: 2, Loss: 8.938960075378418\n",
      "Epoch: 3, Loss: 9.57465648651123\n",
      "Epoch: 4, Loss: 10.780704498291016\n",
      "Epoch: 5, Loss: 7.932991027832031\n",
      "Epoch: 6, Loss: 5.075913429260254\n",
      "Epoch: 7, Loss: 4.248150825500488\n",
      "Epoch: 8, Loss: 4.191751480102539\n",
      "Epoch: 9, Loss: 3.8594160079956055\n",
      "Training GCN model 1...\n",
      "Epoch: 0, Loss: 15.68592357635498\n",
      "Epoch: 1, Loss: 36.39560317993164\n",
      "Epoch: 2, Loss: 12.721116065979004\n",
      "Epoch: 3, Loss: 9.68607234954834\n",
      "Epoch: 4, Loss: 9.990828514099121\n",
      "Epoch: 5, Loss: 10.159845352172852\n",
      "Epoch: 6, Loss: 8.696839332580566\n",
      "Epoch: 7, Loss: 7.103578567504883\n",
      "Epoch: 8, Loss: 5.681501388549805\n",
      "Epoch: 9, Loss: 4.806699275970459\n",
      "Training GCN model 2...\n",
      "Epoch: 0, Loss: 14.628486633300781\n",
      "Epoch: 1, Loss: 7.333364963531494\n",
      "Epoch: 2, Loss: 4.2404704093933105\n",
      "Epoch: 3, Loss: 2.6630125045776367\n",
      "Epoch: 4, Loss: 1.9667813777923584\n",
      "Epoch: 5, Loss: 1.6482360363006592\n",
      "Epoch: 6, Loss: 1.4198163747787476\n",
      "Epoch: 7, Loss: 1.2138973474502563\n",
      "Epoch: 8, Loss: 1.0272581577301025\n",
      "Epoch: 9, Loss: 0.8568751811981201\n",
      "Training classifier...\n",
      "Epoch: 0, Loss: 0.7005723118782043\n",
      "Epoch: 1, Loss: 0.6764406561851501\n",
      "Epoch: 2, Loss: 0.6547293663024902\n",
      "Epoch: 3, Loss: 0.6335553526878357\n",
      "Epoch: 4, Loss: 0.6123350262641907\n",
      "Epoch: 5, Loss: 0.5902743339538574\n",
      "Epoch: 6, Loss: 0.566758930683136\n",
      "Epoch: 7, Loss: 0.5423477292060852\n",
      "Epoch: 8, Loss: 0.5184653401374817\n",
      "Epoch: 9, Loss: 0.4963284432888031\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from itertools import combinations\n",
    "\n",
    "# Step 2: GCN Model\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Step 3: Sampling Pairs\n",
    "def sample_pairs(labels):\n",
    "    \"\"\"\n",
    "    Generate positive and negative pairs from the labels.\n",
    "\n",
    "    Args:\n",
    "    - labels (torch.Tensor): Labels of the nodes.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple[int, int]]: Positive and negative pairs (indices of nodes).\n",
    "    \"\"\"\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    for i, j in combinations(range(len(labels)), 2):\n",
    "        if labels[i] == labels[j]:\n",
    "            positive_pairs.append((i, j))\n",
    "        else:\n",
    "            negative_pairs.append((i, j))\n",
    "    return positive_pairs, negative_pairs\n",
    "\n",
    "# Step 4: Contrastive Loss\n",
    "def pairwise_contrastive_loss(embeddings, positive_pairs, negative_pairs, margin=1.0):\n",
    "    \"\"\"\n",
    "    Compute contrastive loss using sampled positive and negative pairs.\n",
    "\n",
    "    Args:\n",
    "    - embeddings (torch.Tensor): Embedding matrix.\n",
    "    - positive_pairs (List[Tuple[int, int]]): Positive pairs.\n",
    "    - negative_pairs (List[Tuple[int, int]]): Negative pairs.\n",
    "    - margin (float): Margin for dissimilar embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Contrastive loss.\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "\n",
    "    # Positive pairs\n",
    "    for i, j in positive_pairs:\n",
    "        dist = torch.norm(embeddings[i] - embeddings[j])\n",
    "        loss += dist ** 2  # Pull closer\n",
    "\n",
    "    # Negative pairs\n",
    "    for i, j in negative_pairs:\n",
    "        dist = torch.norm(embeddings[i] - embeddings[j])\n",
    "        loss += torch.clamp(margin - dist, min=0) ** 2  # Push apart\n",
    "\n",
    "    return loss / (len(positive_pairs) + len(negative_pairs))\n",
    "\n",
    "# Step 5: Classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Example thresholds and data\n",
    "thresholds = [0.8, 0.8, 0.8]\n",
    "\n",
    "# Create graphs for each modality\n",
    "graphs = [create_graph(data, threshold) for data, threshold in zip(train_modalities, thresholds)]\n",
    "\n",
    "# Initialize GCN models for each modality\n",
    "gcn_models = []\n",
    "cln_model = GCNEncoder(input_dim=19, hidden_dim=32, output_dim=16)\n",
    "cnv_model = GCNEncoder(input_dim=500, hidden_dim=32, output_dim=16)\n",
    "dna_model = GCNEncoder(input_dim=500, hidden_dim=32, output_dim=16)\n",
    "mir_model = GCNEncoder(input_dim=500, hidden_dim=32, output_dim=16)\n",
    "mrna_model = GCNEncoder(input_dim=500, hidden_dim=32, output_dim=16)\n",
    "wsi_model = GCNEncoder(input_dim=800, hidden_dim=32, output_dim=16)\n",
    "gcn_models = [mir_model, mrna_model, wsi_model]\n",
    "optimizers = [torch.optim.Adam(model.parameters(), lr=0.01) for model in gcn_models]\n",
    "\n",
    "# Training GCNs\n",
    "epochs = 10\n",
    "for i, (model, graph, optimizer) in enumerate(zip(gcn_models, graphs, optimizers)):\n",
    "    print(f'Training GCN model {i}...')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings = model(graph.x, graph.edge_index)\n",
    "\n",
    "        # Sample pairs and compute loss\n",
    "        positive_pairs, negative_pairs = sample_pairs(labels_train)\n",
    "        loss = pairwise_contrastive_loss(embeddings, positive_pairs, negative_pairs)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Concatenate embeddings from all modalities\n",
    "all_embeddings = []\n",
    "for model, graph in zip(gcn_models, graphs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(graph.x, graph.edge_index)\n",
    "        all_embeddings.append(embeddings)\n",
    "concatenated_embeddings = torch.cat(all_embeddings, dim=1)\n",
    "\n",
    "# Initialize and train the classifier\n",
    "classifier = Classifier(input_dim=concatenated_embeddings.size(1), hidden_dim=32, num_classes=2)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Training classifier...\")\n",
    "for epoch in range(epochs):\n",
    "    classifier.train()\n",
    "    classifier_optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass and compute loss\n",
    "    logits = classifier(concatenated_embeddings)\n",
    "    classification_loss = F.cross_entropy(logits, labels_train)\n",
    "    classification_loss.backward()\n",
    "    classifier_optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {classification_loss.item()}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 319, Number of edges: 22\n",
      "Number of nodes: 319, Number of edges: 157\n",
      "Number of nodes: 319, Number of edges: 167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6991\n",
      "Test F1 Score: 0.6928\n",
      "Test AUC: 0.7787\n",
      "Test Specificity: 0.5570\n",
      "Test Recall: 0.8385\n",
      "Test Precision: 0.6585\n",
      "Test MCC: 0.4126\n",
      "Test AUPRC: 0.7735\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65       158\n",
      "           1       0.66      0.84      0.74       161\n",
      "\n",
      "    accuracy                           0.70       319\n",
      "   macro avg       0.72      0.70      0.69       319\n",
      "weighted avg       0.71      0.70      0.69       319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef, recall_score, precision_score, average_precision_score\n",
    "import seaborn as sns\n",
    "thresholds = [0.95, 0.7, 0.5, 0.5, 0.2]\n",
    "# Create graphs for the test modalities\n",
    "test_graphs = [create_graph(data, threshold) for data, threshold in zip(test_modalities, thresholds)]\n",
    "# Generate embeddings for test graphs using trained GCN models\n",
    "test_embeddings_list = []\n",
    "for model, test_graph in zip(gcn_models, test_graphs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(test_graph.x, test_graph.edge_index)\n",
    "        test_embeddings_list.append(embeddings)\n",
    "\n",
    "# Concatenate embeddings across modalities\n",
    "concatenated_test_embeddings = torch.cat(test_embeddings_list, dim=1)\n",
    "# Evaluate the classifier on the test set\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = classifier(concatenated_test_embeddings)\n",
    "    test_prob = F.softmax(test_logits, dim=1)\n",
    "    test_pred = (test_prob[:, 1] > 0.5).long()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Convert tensors to numpy arrays for metrics calculation\n",
    "labels_test_np = labels_test.cpu().numpy()\n",
    "test_pred_np = test_pred.cpu().numpy()\n",
    "test_prob_np = test_prob.cpu().numpy()\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(labels_test_np, test_pred_np)\n",
    "f1 = f1_score(labels_test_np, test_pred_np, average='weighted')\n",
    "auc = roc_auc_score(labels_test_np, test_prob_np[:, 1])\n",
    "cm = confusion_matrix(labels_test_np, test_pred_np)\n",
    "specificity = cm[0, 0] / cm[0, :].sum()\n",
    "recall = recall_score(labels_test_np, test_pred_np)\n",
    "precision = precision_score(labels_test_np, test_pred_np)\n",
    "mcc = matthews_corrcoef(labels_test_np, test_pred_np)\n",
    "auprc = average_precision_score(labels_test_np, test_prob_np[:, 1])\n",
    "classification_rep = classification_report(labels_test_np, test_pred_np)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 16})\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test Specificity: {specificity:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test MCC: {mcc:.4f}\")\n",
    "print(f\"Test AUPRC: {auprc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
